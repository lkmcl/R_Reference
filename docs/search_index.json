[["index.html", "R Reference Manual Chapter 1 R Basics 1.1 Introduction 1.2 Characters 1.3 Lists 1.4 Factors 1.5 Matrices 1.6 Dataframe 1.7 Conditionals 1.8 Loops 1.9 Functions 1.10 Practice Problems", " R Reference Manual Logan McLaurin 2024-07-18 Chapter 1 R Basics 1.1 Introduction 1.1.1 Operators R Operators Math Functions 1.1.2 Variables vector: a collection of values, created by using R’s “combine” function c() must be same datatype numeric: Numbers including floating point and integer values integer: integer variables, whole number values having no fractional part Often suffixed with L, var &lt;- 10L complex: complex numbers var &lt;- 9 + 3i character: variables made up of strings (not a datatype itself) any quotes are fine logical 1.2 Characters 1.2.1 Paste function paste(s, t, sep= \" \", collapse=null): concatenate s and t, returning a new character as a result. sep defines character used to separate s and t (default is space) collapse is used when s and t are vectors. (NULL concatenates each vector separately) ## Strings paste( &quot;hello&quot;, &quot;world!&quot;, sep=&quot;.&quot; ) ## [1] &quot;hello.world!&quot; ## Concatenates elementwise a &lt;- c( &quot;1&quot;, &quot;2&quot;, &quot;3&quot; ) b &lt;- c( &quot;a&quot;, &quot;b&quot;, &quot;c&quot; ) paste( a, b ) ## [1] &quot;1 a&quot; &quot;2 b&quot; &quot;3 c&quot; # Example collapse which gives a string paste( a, b, collapse=&quot;; &quot; ) ## [1] &quot;1 a; 2 b; 3 c&quot; 1.2.2 Other character functions substring(s, i, j) : returns ith through jth character. (s, i) retursn substring from ith until the last character nchar(s) : number of characters in s s &lt;- &quot;hello world!&quot; print( nchar( s ) ) ## [1] 12 print( substring( s, 7, 7 ) ) ## [1] &quot;w&quot; print( substring( s, 3, 8 ) ) ## [1] &quot;llo wo&quot; print( substring( s, 4 ) ) ## [1] &quot;lo world!&quot; print( substring( s, nchar( s ) - 1 ), nchar( s ) - 1 ) ## [1] &quot;d!&quot; print( substring( s, nchar( s ) - 2 ) ) ## [1] &quot;ld!&quot; t &lt;- &quot;must.. try.. harder..&quot; print( paste( s, t ) ) ## [1] &quot;hello world! must.. try.. harder..&quot; 1.3 Lists Can take any datatype and include keyed values l &lt;- list(&quot;values&quot;=sin(1:3), &quot;ids&quot;=letters[1:3], &quot;sub&quot;=list(&quot;foo&quot;=42,&quot;bar&quot;=13), &quot;greeting&quot;=&quot;Hello&quot;) # Can return entry wise as a sublist l[1] or as values with l[[1]] print( l[&#39;values&#39;] ) ## $values ## [1] 0.8414710 0.9092974 0.1411200 str(l[&#39;values&#39;]) ## List of 1 ## $ values: num [1:3] 0.841 0.909 0.141 print( l[[&quot;ids&quot;]] ) ## [1] &quot;a&quot; &quot;b&quot; &quot;c&quot; print( l$sub$foo ) ## [1] 42 print( l[[c(3,2)]] ) ## [1] 13 1.4 Factors city &lt;- c(3, 2, 1, 4, 3, 2) city_nm &lt;- c( &quot;Dublin&quot;, &quot;London&quot;, &quot;Sofia&quot;, &quot;Ponteverdra&quot; ) f &lt;- factor( city, labels=city_nm ) print(f) ## [1] Sofia London Dublin Ponteverdra Sofia London ## Levels: Dublin London Sofia Ponteverdra ## Appending factors new_f &lt;- append( f, as.factor( c( &quot;Zurich&quot;, &quot;Berlin&quot; ) ) ) print(new_f) ## [1] Sofia London Dublin Ponteverdra Sofia London ## [7] Zurich Berlin ## Levels: Dublin London Sofia Ponteverdra Berlin Zurich 1.5 Matrices mat &lt;- matrix( c( 1, 2, 3, 4, 5, 6 ), nrow=3, ncol=2 ) print(mat) ## [,1] [,2] ## [1,] 1 4 ## [2,] 2 5 ## [3,] 3 6 Slicing matrix print(mat[1,1]) ## [1] 1 print(mat[2,]) ## [1] 2 5 print(mat[ c(2,3), ]) ## [,1] [,2] ## [1,] 2 5 ## [2,] 3 6 Binding rows and columns mat &lt;- cbind( mat, c( 7, 8, 9 ), c( 10, 11,12 ) ) print(mat) ## [,1] [,2] [,3] [,4] ## [1,] 1 4 7 10 ## [2,] 2 5 8 11 ## [3,] 3 6 9 12 1.6 Dataframe Column names are non-empty Row names are unique Data in a dataframe is numeric, character, or factor Each column has the same number of values df &lt;- data.frame( emp_id &lt;- c(1:5), emp_nm &lt;- c( &quot;Rick&quot;, &quot;Dan&quot;, &quot;Michelle&quot;, &quot;Ryan&quot;, &quot;Gary&quot; ), salary &lt;- c(623.3, 515.2, 611.0, 729.0, 843.25), start_dt &lt;- as.Date(c(&quot;2012-01-01&quot;, &quot;2013-09-23&quot;, &quot;2014-11-15&quot;, &quot;2014-05-11&quot;, &quot;2015-03-27&quot;)) ) print(df) ## emp_id....c.1.5. emp_nm....c..Rick....Dan....Michelle....Ryan....Gary.. ## 1 1 Rick ## 2 2 Dan ## 3 3 Michelle ## 4 4 Ryan ## 5 5 Gary ## salary....c.623.3..515.2..611..729..843.25. ## 1 623.30 ## 2 515.20 ## 3 611.00 ## 4 729.00 ## 5 843.25 ## start_dt....as.Date.c..2012.01.01....2013.09.23....2014.11.15... ## 1 2012-01-01 ## 2 2013-09-23 ## 3 2014-11-15 ## 4 2014-05-11 ## 5 2015-03-27 str(df) ## &#39;data.frame&#39;: 5 obs. of 4 variables: ## $ emp_id....c.1.5. : int 1 2 3 4 5 ## $ emp_nm....c..Rick....Dan....Michelle....Ryan....Gary.. : chr &quot;Rick&quot; &quot;Dan&quot; &quot;Michelle&quot; &quot;Ryan&quot; ... ## $ salary....c.623.3..515.2..611..729..843.25. : num 623 515 611 729 843 ## $ start_dt....as.Date.c..2012.01.01....2013.09.23....2014.11.15...: Date, format: &quot;2012-01-01&quot; &quot;2013-09-23&quot; ... ## Use the summary function summary(df) ## emp_id....c.1.5. emp_nm....c..Rick....Dan....Michelle....Ryan....Gary.. ## Min. :1 Length:5 ## 1st Qu.:2 Class :character ## Median :3 Mode :character ## Mean :3 ## 3rd Qu.:4 ## Max. :5 ## salary....c.623.3..515.2..611..729..843.25. ## Min. :515.2 ## 1st Qu.:611.0 ## Median :623.3 ## Mean :664.4 ## 3rd Qu.:729.0 ## Max. :843.2 ## start_dt....as.Date.c..2012.01.01....2013.09.23....2014.11.15... ## Min. :2012-01-01 ## 1st Qu.:2013-09-23 ## Median :2014-05-11 ## Mean :2014-01-14 ## 3rd Qu.:2014-11-15 ## Max. :2015-03-27 dept_c &lt;- c( &quot;IT&quot;, &quot;Finance&quot;, &quot;HR&quot; ) vacn_c &lt;- c( &quot;Jun&quot;, &quot;Jan&quot;, &quot;May&quot;, &quot;Dec&quot;, &quot;Oct&quot;, &quot;Mar&quot; ) length( dept_c ) &lt;- nrow( df ) length( vacn_c ) &lt;- nrow( df ) df$dept &lt;- dept_c df$vacation &lt;- vacn_c print(df) ## emp_id....c.1.5. emp_nm....c..Rick....Dan....Michelle....Ryan....Gary.. ## 1 1 Rick ## 2 2 Dan ## 3 3 Michelle ## 4 4 Ryan ## 5 5 Gary ## salary....c.623.3..515.2..611..729..843.25. ## 1 623.30 ## 2 515.20 ## 3 611.00 ## 4 729.00 ## 5 843.25 ## start_dt....as.Date.c..2012.01.01....2013.09.23....2014.11.15... dept ## 1 2012-01-01 IT ## 2 2013-09-23 Finance ## 3 2014-11-15 HR ## 4 2014-05-11 &lt;NA&gt; ## 5 2015-03-27 &lt;NA&gt; ## vacation ## 1 Jun ## 2 Jan ## 3 May ## 4 Dec ## 5 Oct Beware of concatenating things of different lengths dept_c &lt;- c( &quot;IT&quot;, &quot;Finance&quot;, &quot;HR&quot; ) vacn_c &lt;- c( &quot;Jun&quot;, &quot;Jan&quot;, &quot;May&quot;, &quot;Dec&quot;, &quot;Oct&quot;, &quot;Mar&quot; ) length( dept_c ) &lt;- nrow( df ) length( vacn_c ) &lt;- nrow( df ) df$dept &lt;- dept_c df$vacation &lt;- vacn_c print(df) ## emp_id....c.1.5. emp_nm....c..Rick....Dan....Michelle....Ryan....Gary.. ## 1 1 Rick ## 2 2 Dan ## 3 3 Michelle ## 4 4 Ryan ## 5 5 Gary ## salary....c.623.3..515.2..611..729..843.25. ## 1 623.30 ## 2 515.20 ## 3 611.00 ## 4 729.00 ## 5 843.25 ## start_dt....as.Date.c..2012.01.01....2013.09.23....2014.11.15... dept ## 1 2012-01-01 IT ## 2 2013-09-23 Finance ## 3 2014-11-15 HR ## 4 2014-05-11 &lt;NA&gt; ## 5 2015-03-27 &lt;NA&gt; ## vacation ## 1 Jun ## 2 Jan ## 3 May ## 4 Dec ## 5 Oct 1.7 Conditionals grade &lt;- 75 if ( grade &gt;= 90 ) { passed &lt;- TRUE letter &lt;- &#39;A&#39; } else if ( grade &gt;= 80 ) { passed &lt;- TRUE letter &lt;- &#39;B&#39; } else if ( grade &gt;= 65 ) { passed &lt;- TRUE letter &lt;- &#39;C&#39; } else if ( grade &gt;= 50 ) { passed &lt;- TRUE letter &lt;- &#39;D&#39; } else { passed &lt;- FALSE letter &lt;- &#39;F&#39; } print( passed ) ## [1] TRUE print( letter ) ## [1] &quot;C&quot; 1.8 Loops While Loop i &lt;- 1 while ( i &lt;= 15 ) { print( paste( &quot;The square root of&quot;, i, &quot;is&quot;, sqrt( i ) ) ) i &lt;- i + 1 } ## [1] &quot;The square root of 1 is 1&quot; ## [1] &quot;The square root of 2 is 1.4142135623731&quot; ## [1] &quot;The square root of 3 is 1.73205080756888&quot; ## [1] &quot;The square root of 4 is 2&quot; ## [1] &quot;The square root of 5 is 2.23606797749979&quot; ## [1] &quot;The square root of 6 is 2.44948974278318&quot; ## [1] &quot;The square root of 7 is 2.64575131106459&quot; ## [1] &quot;The square root of 8 is 2.82842712474619&quot; ## [1] &quot;The square root of 9 is 3&quot; ## [1] &quot;The square root of 10 is 3.16227766016838&quot; ## [1] &quot;The square root of 11 is 3.3166247903554&quot; ## [1] &quot;The square root of 12 is 3.46410161513775&quot; ## [1] &quot;The square root of 13 is 3.60555127546399&quot; ## [1] &quot;The square root of 14 is 3.74165738677394&quot; ## [1] &quot;The square root of 15 is 3.87298334620742&quot; For loop: fruit &lt;- list( &quot;apple&quot;, &quot;banana&quot;, &quot;cherry&quot; ) for ( nm in fruit ) { print( paste( nm, &#39;(&#39;, nchar( nm ), &#39;)&#39; ) ) } ## [1] &quot;apple ( 5 )&quot; ## [1] &quot;banana ( 6 )&quot; ## [1] &quot;cherry ( 6 )&quot; break and next are using for stopping loop operations. seq function has (start, stop, interval) 1.9 Functions max_val &lt;- function( num_l ) { if ( length( num_l ) &lt;= 0 ) { return( NULL ) } max_v &lt;- num_l[[1]] for ( elem in num_l ) { if ( elem &gt; max_v ) { max_v &lt;- elem } } return( max_v ) } max_val(c(4, 44, 23, -3, 4, 333, -343)) ## [1] 333 1.10 Practice Problems 1.10.1 List Practice db &lt;- list(beaver = &quot;colony&quot;, crow = &quot;murder&quot;, parrot = &quot;pandemonium&quot;, porcupine = &quot;prickle&quot;) for (animal in names(db)){ print(paste(animal, &quot;:&quot;, db[[animal]])) } ## [1] &quot;beaver : colony&quot; ## [1] &quot;crow : murder&quot; ## [1] &quot;parrot : pandemonium&quot; ## [1] &quot;porcupine : prickle&quot; "],["tidyverse.html", "Chapter 2 Tidyverse 2.1 Cheat Sheets 2.2 Basics 2.3 Data Manipulation", " Chapter 2 Tidyverse 2.1 Cheat Sheets 2.1.1 dplyr: data manipulation 2.1.2 forcats: categorical 2.1.3 ggplot2: visualization 2.1.4 lubridate: datetimes 2.1.5 purrr: functions and vectors 2.1.6 readr: reading 2.1.7 stringr: strings 2.1.8 tidyr: data wrangling 2.2 Basics Differences between tibbles and dataframes relate to printing and subsetting ~ operator separates arguments to a formula . operater is short for all columns %&gt;% operator allows chaining of sequences to apply over single statements 2.2.1 Tidy Data Every variable is stored in its own column Every observation or sample is stored in its own row Every value is stored in its own cell 2.2.2 Pivot pivot_longer handles variables spread over multiple columns pivot_wider handles variables spread over multiple rows pivot_longer example: library(tidyverse) ## ── Attaching core tidyverse packages ───────────────────────────────── tidyverse 2.0.0 ── ## ✔ dplyr 1.1.4 ✔ readr 2.1.5 ## ✔ forcats 1.0.0 ✔ stringr 1.5.1 ## ✔ ggplot2 3.5.1 ✔ tibble 3.2.1 ## ✔ lubridate 1.9.3 ✔ tidyr 1.3.1 ## ✔ purrr 1.0.2 ## ── Conflicts ─────────────────────────────────────────────────── tidyverse_conflicts() ── ## ✖ dplyr::filter() masks stats::filter() ## ✖ dplyr::lag() masks stats::lag() ## ℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors tib &lt;- as_tibble( matrix( nrow=3, ncol=3 ) ) ## Warning: The `x` argument of `as_tibble.matrix()` must have unique column names if `.name_repair` ## is omitted as of tibble 2.0.0. ## ℹ Using compatibility `.name_repair`. ## This warning is displayed once every 8 hours. ## Call `lifecycle::last_lifecycle_warnings()` to see where this warning was generated. colnames(tib) &lt;- c( &quot;country&quot;, &quot;1999&quot;, &quot;2000&quot; ) tib$country &lt;- c( &quot;Afghanistan&quot;, &quot;Brazil&quot;, &quot;China&quot; ) tib$&quot;1999&quot; &lt;- c(745, 37737, 212258) tib$&quot;2000&quot; &lt;- c(2666, 80488, 213766) print( tib ) ## # A tibble: 3 × 3 ## country `1999` `2000` ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Afghanistan 745 2666 ## 2 Brazil 37737 80488 ## 3 China 212258 213766 ## requires you to define which columns are values and not variables (the years 1999 and 2000, in our example), the name of the new column to move the column names to, and the name of the new column to move corresponding column values to tib %&gt;% pivot_longer(c(&quot;1999&quot;, &quot;2000&quot;), names_to = &quot;year&quot;, values_to = &quot;cases&quot;) ## # A tibble: 6 × 3 ## country year cases ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 Afghanistan 1999 745 ## 2 Afghanistan 2000 2666 ## 3 Brazil 1999 37737 ## 4 Brazil 2000 80488 ## 5 China 1999 212258 ## 6 China 2000 213766 pivot_wider example library(vctrs) ## ## Attaching package: &#39;vctrs&#39; ## The following object is masked from &#39;package:dplyr&#39;: ## ## data_frame ## The following object is masked from &#39;package:tibble&#39;: ## ## data_frame tib &lt;- as_tibble( matrix( nrow=12, ncol=4 ) ) colnames(tib) &lt;- c( &quot;country&quot;, &quot;year&quot;, &quot;type&quot;, &quot;count&quot; ) tib$country &lt;- vec_rep_each( c( &quot;Afghanistan&quot;, &quot;Brazil&quot;, &quot;China&quot; ), times=4 ) tib$year &lt;- vec_rep( c( 1999, 1999, 2000, 2000 ), times=3 ) tib$type &lt;- vec_rep( c( &quot;cases&quot;, &quot;population&quot; ), times=6 ) tib$count &lt;- c( 745, 19987071, 2666, 20595360, 37737, 172006362, 80488, 174504898, 212258, 127295272, 213766, 1280428583 ) print(tib) ## # A tibble: 12 × 4 ## country year type count ## &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 Afghanistan 1999 cases 745 ## 2 Afghanistan 1999 population 19987071 ## 3 Afghanistan 2000 cases 2666 ## 4 Afghanistan 2000 population 20595360 ## 5 Brazil 1999 cases 37737 ## 6 Brazil 1999 population 172006362 ## 7 Brazil 2000 cases 80488 ## 8 Brazil 2000 population 174504898 ## 9 China 1999 cases 212258 ## 10 China 1999 population 127295272 ## 11 China 2000 cases 213766 ## 12 China 2000 population 1280428583 ## store type in single tibble row. provide the columns to take the new variable names from (type in the current tibble) and the column to take the corresponding values from (count) tib %&gt;% pivot_wider( names_from = &quot;type&quot;, values_from = &quot;count&quot;) ## # A tibble: 6 × 4 ## country year cases population ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Afghanistan 1999 745 19987071 ## 2 Afghanistan 2000 2666 20595360 ## 3 Brazil 1999 37737 172006362 ## 4 Brazil 2000 80488 174504898 ## 5 China 1999 212258 127295272 ## 6 China 2000 213766 1280428583 2.3 Data Manipulation print(starwars) ## # A tibble: 87 × 14 ## name height mass hair_color skin_color eye_color birth_year sex gender ## &lt;chr&gt; &lt;int&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; ## 1 Luke Sk… 172 77 blond fair blue 19 male mascu… ## 2 C-3PO 167 75 &lt;NA&gt; gold yellow 112 none mascu… ## 3 R2-D2 96 32 &lt;NA&gt; white, bl… red 33 none mascu… ## 4 Darth V… 202 136 none white yellow 41.9 male mascu… ## 5 Leia Or… 150 49 brown light brown 19 fema… femin… ## 6 Owen La… 178 120 brown, gr… light blue 52 male mascu… ## 7 Beru Wh… 165 75 brown light blue 47 fema… femin… ## 8 R5-D4 97 32 &lt;NA&gt; white, red red NA none mascu… ## 9 Biggs D… 183 84 black light brown 24 male mascu… ## 10 Obi-Wan… 182 77 auburn, w… fair blue-gray 57 male mascu… ## # ℹ 77 more rows ## # ℹ 5 more variables: homeworld &lt;chr&gt;, species &lt;chr&gt;, films &lt;list&gt;, ## # vehicles &lt;list&gt;, starships &lt;list&gt; 2.3.1 Rows filter(): Choose rows based on column values print( starwars %&gt;% filter( skin_color==&quot;light&quot;, eye_color==&quot;blue&quot; ) ) ## # A tibble: 3 × 14 ## name height mass hair_color skin_color eye_color birth_year sex gender ## &lt;chr&gt; &lt;int&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; ## 1 Owen Lars 178 120 brown, gr… light blue 52 male mascu… ## 2 Beru Whi… 165 75 brown light blue 47 fema… femin… ## 3 Lobot 175 79 none light blue 37 male mascu… ## # ℹ 5 more variables: homeworld &lt;chr&gt;, species &lt;chr&gt;, films &lt;list&gt;, ## # vehicles &lt;list&gt;, starships &lt;list&gt; slice(): choose rows based on location print( starwars %&gt;% slice(5:10) ) # Return rows 5-10 inclusive ## # A tibble: 6 × 14 ## name height mass hair_color skin_color eye_color birth_year sex gender ## &lt;chr&gt; &lt;int&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; ## 1 Leia Org… 150 49 brown light brown 19 fema… femin… ## 2 Owen Lars 178 120 brown, gr… light blue 52 male mascu… ## 3 Beru Whi… 165 75 brown light blue 47 fema… femin… ## 4 R5-D4 97 32 &lt;NA&gt; white, red red NA none mascu… ## 5 Biggs Da… 183 84 black light brown 24 male mascu… ## 6 Obi-Wan … 182 77 auburn, w… fair blue-gray 57 male mascu… ## # ℹ 5 more variables: homeworld &lt;chr&gt;, species &lt;chr&gt;, films &lt;list&gt;, ## # vehicles &lt;list&gt;, starships &lt;list&gt; arrange(): change row order print( starwars %&gt;% arrange( height, mass ) ) # Sort rows by height, within height by mass ## # A tibble: 87 × 14 ## name height mass hair_color skin_color eye_color birth_year sex gender ## &lt;chr&gt; &lt;int&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; ## 1 Yoda 66 17 white green brown 896 male mascu… ## 2 Ratts T… 79 15 none grey, blue unknown NA male mascu… ## 3 Wicket … 88 20 brown brown brown 8 male mascu… ## 4 Dud Bolt 94 45 none blue, grey yellow NA male mascu… ## 5 R2-D2 96 32 &lt;NA&gt; white, bl… red 33 none mascu… ## 6 R4-P17 96 NA none silver, r… red, blue NA none femin… ## 7 R5-D4 97 32 &lt;NA&gt; white, red red NA none mascu… ## 8 Sebulba 112 40 none grey, red orange NA male mascu… ## 9 Gasgano 122 NA none white, bl… black NA male mascu… ## 10 Watto 137 NA black blue, grey yellow NA male mascu… ## # ℹ 77 more rows ## # ℹ 5 more variables: homeworld &lt;chr&gt;, species &lt;chr&gt;, films &lt;list&gt;, ## # vehicles &lt;list&gt;, starships &lt;list&gt; 2.3.2 Columns select(): chooses a subset of columns print( starwars %&gt;% select( name, hair_color, eye_color ) ) # Select name, hair colour, eye colour columns ## # A tibble: 87 × 3 ## name hair_color eye_color ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 Luke Skywalker blond blue ## 2 C-3PO &lt;NA&gt; yellow ## 3 R2-D2 &lt;NA&gt; red ## 4 Darth Vader none yellow ## 5 Leia Organa brown brown ## 6 Owen Lars brown, grey blue ## 7 Beru Whitesun Lars brown blue ## 8 R5-D4 &lt;NA&gt; red ## 9 Biggs Darklighter black brown ## 10 Obi-Wan Kenobi auburn, white blue-gray ## # ℹ 77 more rows print( starwars %&gt;% select( name:eye_color ) ) # Select columns from name to eye colour ## # A tibble: 87 × 6 ## name height mass hair_color skin_color eye_color ## &lt;chr&gt; &lt;int&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 Luke Skywalker 172 77 blond fair blue ## 2 C-3PO 167 75 &lt;NA&gt; gold yellow ## 3 R2-D2 96 32 &lt;NA&gt; white, blue red ## 4 Darth Vader 202 136 none white yellow ## 5 Leia Organa 150 49 brown light brown ## 6 Owen Lars 178 120 brown, grey light blue ## 7 Beru Whitesun Lars 165 75 brown light blue ## 8 R5-D4 97 32 &lt;NA&gt; white, red red ## 9 Biggs Darklighter 183 84 black light brown ## 10 Obi-Wan Kenobi 182 77 auburn, white fair blue-gray ## # ℹ 77 more rows print( starwars %&gt;% select( ends_with( &quot;color&quot; ) ) ) # Selects columns whose name ends w/color ## # A tibble: 87 × 3 ## hair_color skin_color eye_color ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 blond fair blue ## 2 &lt;NA&gt; gold yellow ## 3 &lt;NA&gt; white, blue red ## 4 none white yellow ## 5 brown light brown ## 6 brown, grey light blue ## 7 brown light blue ## 8 &lt;NA&gt; white, red red ## 9 black light brown ## 10 auburn, white fair blue-gray ## # ℹ 77 more rows rename(): Renames a column. print( starwars %&gt;% rename( &quot;Home.World&quot;=&quot;homeworld&quot; ) ) # Rename homeworld column to Home.World ## # A tibble: 87 × 14 ## name height mass hair_color skin_color eye_color birth_year sex gender ## &lt;chr&gt; &lt;int&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; ## 1 Luke Sk… 172 77 blond fair blue 19 male mascu… ## 2 C-3PO 167 75 &lt;NA&gt; gold yellow 112 none mascu… ## 3 R2-D2 96 32 &lt;NA&gt; white, bl… red 33 none mascu… ## 4 Darth V… 202 136 none white yellow 41.9 male mascu… ## 5 Leia Or… 150 49 brown light brown 19 fema… femin… ## 6 Owen La… 178 120 brown, gr… light blue 52 male mascu… ## 7 Beru Wh… 165 75 brown light blue 47 fema… femin… ## 8 R5-D4 97 32 &lt;NA&gt; white, red red NA none mascu… ## 9 Biggs D… 183 84 black light brown 24 male mascu… ## 10 Obi-Wan… 182 77 auburn, w… fair blue-gray 57 male mascu… ## # ℹ 77 more rows ## # ℹ 5 more variables: Home.World &lt;chr&gt;, species &lt;chr&gt;, films &lt;list&gt;, ## # vehicles &lt;list&gt;, starships &lt;list&gt; mutate(): Changes the values of a column or creates new column(s). print(starwars %&gt;% mutate( height_m = height / 100, BMI = mass / ( height_m ^ 2 ) ) %&gt;% select( BMI, height_m, everything() )) ## # A tibble: 87 × 16 ## BMI height_m name height mass hair_color skin_color eye_color birth_year ## &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;int&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 26.0 1.72 Luke … 172 77 blond fair blue 19 ## 2 26.9 1.67 C-3PO 167 75 &lt;NA&gt; gold yellow 112 ## 3 34.7 0.96 R2-D2 96 32 &lt;NA&gt; white, bl… red 33 ## 4 33.3 2.02 Darth… 202 136 none white yellow 41.9 ## 5 21.8 1.5 Leia … 150 49 brown light brown 19 ## 6 37.9 1.78 Owen … 178 120 brown, gr… light blue 52 ## 7 27.5 1.65 Beru … 165 75 brown light blue 47 ## 8 34.0 0.97 R5-D4 97 32 &lt;NA&gt; white, red red NA ## 9 25.1 1.83 Biggs… 183 84 black light brown 24 ## 10 23.2 1.82 Obi-W… 182 77 auburn, w… fair blue-gray 57 ## # ℹ 77 more rows ## # ℹ 7 more variables: sex &lt;chr&gt;, gender &lt;chr&gt;, homeworld &lt;chr&gt;, species &lt;chr&gt;, ## # films &lt;list&gt;, vehicles &lt;list&gt;, starships &lt;list&gt; relocate(): Changes the order or columns. print(starwars %&gt;% relocate( sex:homeworld, .before=height )) ## # A tibble: 87 × 14 ## name sex gender homeworld height mass hair_color skin_color eye_color ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;int&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 Luke Sky… male mascu… Tatooine 172 77 blond fair blue ## 2 C-3PO none mascu… Tatooine 167 75 &lt;NA&gt; gold yellow ## 3 R2-D2 none mascu… Naboo 96 32 &lt;NA&gt; white, bl… red ## 4 Darth Va… male mascu… Tatooine 202 136 none white yellow ## 5 Leia Org… fema… femin… Alderaan 150 49 brown light brown ## 6 Owen Lars male mascu… Tatooine 178 120 brown, gr… light blue ## 7 Beru Whi… fema… femin… Tatooine 165 75 brown light blue ## 8 R5-D4 none mascu… Tatooine 97 32 &lt;NA&gt; white, red red ## 9 Biggs Da… male mascu… Tatooine 183 84 black light brown ## 10 Obi-Wan … male mascu… Stewjon 182 77 auburn, w… fair blue-gray ## # ℹ 77 more rows ## # ℹ 5 more variables: birth_year &lt;dbl&gt;, species &lt;chr&gt;, films &lt;list&gt;, ## # vehicles &lt;list&gt;, starships &lt;list&gt; 2.3.3 Grouping summarise(): collapse a group of rows into single row print(starwars %&gt;% group_by( species, sex ) %&gt;% dplyr::summarise( height=mean(height, na.rm=TRUE ), mass=mean(mass, na.rm=TRUE) ) %&gt;% select( height, mass )) ## `summarise()` has grouped output by &#39;species&#39;. You can override using the `.groups` ## argument. ## Adding missing grouping variables: `species` ## # A tibble: 41 × 3 ## # Groups: species [38] ## species height mass ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Aleena 79 15 ## 2 Besalisk 198 102 ## 3 Cerean 198 82 ## 4 Chagrian 196 NaN ## 5 Clawdite 168 55 ## 6 Droid 131. 69.8 ## 7 Dug 112 40 ## 8 Ewok 88 20 ## 9 Geonosian 183 80 ## 10 Gungan 209. 74 ## # ℹ 31 more rows 2.3.4 "],["common-processes.html", "Chapter 3 Common Processes 3.1 Change Column Types 3.2 Split a String Column into Multiple Columns 3.3 Drop a Column 3.4 Change a Column by a Condition 3.5 Change a Column by Multiple Conditions 3.6 Split a Dataset into Training and Testing", " Chapter 3 Common Processes Combinations of functions that are commonly used in data processing tasks. 3.1 Change Column Types Col1, Col2, Col3 are columns that we want to change to factors data &lt;- data %&gt;% mutate(across(c(Col1, Col2, Col3), as.factor)) c(Col1, Col2, Col3) selects Col1, Col2, and Col3 If we want to change all columns except for Col4 and Col5 to factor data &lt;- data %&gt;% mutate(across(-c(Col4, Col5), as.factor)) -c(Col4, Col5) represents not Col4 or Col5 3.2 Split a String Column into Multiple Columns data %&gt;% separate_wider_delim(Combined_Col, delim=&quot;,&quot;, names = c(&quot;Col1&quot;, &quot;Col2&quot;)) 3.3 Drop a Column data &lt;- data %&gt;% select(-Col_To_Drop) select(-Col_To_Drop) selects all Columns except for Col_To_Drop 3.4 Change a Column by a Condition data &lt;- data %&gt;% mutate(Col1 = ifelse(Col1 &gt; 0, Col1 + Col2, Col1)) Col1 &gt; 0 is a conditional that is being tested Col1 + Col2 is what happens when the conditional (Col1 &gt; 0 in this example) is True Col1 is what happens when the conditional is False 3.5 Change a Column by Multiple Conditions Can use multiple mutate + if_else calls, or can use case_when **Be careful with case_when() because the order of tests matters, just like a series of if-else statements. df &lt;- df %&gt;% mutate(Country = case_when( Country == &quot;US&quot; ~ &quot;United States&quot;, Country == &quot;U.S.A&quot; ~ &quot;United States&quot;, Country == &quot;U.S.&quot; ~ &quot;United States&quot;, Country == &quot;USA&quot; ~ &quot;United States&quot;, Country == &quot;United States of America&quot; ~ &quot;United States&quot;, Country == &quot;The United States&quot; ~ &quot;United States&quot;, Country == &quot;united states&quot; ~ &quot;United States&quot;, Country == &quot;Durham&quot; ~ &quot;United States&quot;, State == &quot;North Carolina&quot; &amp; is.na(Country) ~ &quot;United States&quot;, .default = Country )) A more efficient approach here would be to use Country %in% c(\"US\", \"U.S.A\", ... \"Durham\", but they produce the same results. Country == \"US\" is the conditional tested. ~ \"United States\" is the result returned when the condition is True. .default = Country returns Country when none of the cases are used. 3.6 Split a Dataset into Training and Testing set.seed(123) data &lt;- data %&gt;% mutate(id = row_number()) # if there is not a index, create one train &lt;- data %&gt;% sample_frac(0.7) test &lt;- anti_join(data, train, by = &#39;id&#39;) 0.7 is the percent of the data to include in the training. "],["functions-1.html", "Chapter 4 Functions 4.1 Data Manipulation Functions 4.2 Time", " Chapter 4 Functions Quick notes on functions that are commonly used in data pre-processing, as well as a link to more detailed documentation. 4.1 Data Manipulation Functions 4.1.1 across() Used to mutate across multiple columns. Example: data &lt;- data %&gt;% mutate(across(c(Col1, Col2), as.factor)) Look at full documentation for more advanced applications Full Documentation 4.1.2 mutate() Used to change or create new columns. Example: df %&gt;% mutate(z = x + y) # create a z column that equal to x + y Full Documentation 4.1.3 if_else() Used to return values based on a conditional statement. Example: if_else(x &lt; 0, &quot;negative&quot;, &quot;positive&quot;, missing = &quot;missing&quot;) Full Documentation 4.1.4 case_when() Used to return values based on multiple conditional statements. Example: case_when( x %% 5 == 0 ~ &quot;fizz&quot;, x %% 7 == 0 ~ &quot;buzz&quot;, x %% 35 == 0 ~ &quot;fizz buzz&quot;, .default = as.character(x) ) Full Documentation 4.1.5 seperate_longer_delim() Used to split a string column into multiple rows. Example: df %&gt;% separate_longer_delim(c(Languages), delim = &quot;,&quot;) # Separate Languages column by &quot;,&quot; separator Full Documentation 4.1.6 seperate_wider_delim() Used to split a string column into multiple columns. Example: df %&gt;% separate_wider_delim(Birth_Month_Year, delim=&quot;, &quot;, names = c(&quot;Month&quot;, &quot;Year&quot;)) Full Documentation 4.1.7 na_if() Sets the value of a column equal to NA based on a condition Example: na_if(y, &quot;&quot;) # y is the column and &quot;&quot; is the value to set to NA Full Documentation ## String Functions ### str_split_fixed() Split string column into character matrix (table) with a column for each split. Example: df %&gt;%mutate(Birth_Month = str_split_fixed(df$Birth_Month_Year, &quot;, &quot;, 2)[,1], Birth_Year = str_split_fixed(df$Birth_Month_Year, &quot;, &quot;, 2)[,2]) Better to use seperate_wider_delim() Full Documentation 4.1.8 grepl() A regex search of a string value that returns True if a string contains a value and False otherwise. Some useful regex things: - ‘[:digit:]’ Digits: 0 1 2 3 4 5 6 7 8 9. - ‘+’ a plus looks for one or more occurrences of the value. Example: “[:digit:]+” looks for one or more digits Example: grepl(&quot;[0-9]&quot;, Birth_Month) # if there is a number in the string return True Full Documentation 4.1.9 str_replace_all() or str_replace() Replace a pattern within a string with another string value. str_replace() for first match and str_replace_all() for all matches. Example: str_replace_all(String, &quot;,&quot;, &quot;&quot;) Full Documentation 4.1.10 str_to_title(), str_to_upper(), str_to_lower(), and str_to_sentence() Ways to change the capitalization of a string. - Title Case - UPPER CASE - lower case - Sentence case - Full Documentation 4.1.11 str_squish() or str_trim() Remove leading and trailing whitespace from a string Full Documentation 4.2 Time A lot of functions do similar things for different time formats. Use lubridate cheatsheet 4.2.1 mdy() Parse a date by Month, Day, and Year from string or int mdy(c(&quot;2-1-20&quot;, &quot;05-04-2019&quot;, 100201)) # returns 2020-02-01 2019-05-04 2001-10-02 Full Documentation 4.2.2 day(), month(), or year() Get specific time out of a date object library(lubridate) # need lubridate for my, month, year functions dates &lt;- my(c(&quot;Apr 2020&quot;, &quot;5, 2024&quot;, &quot;December 20&quot;)) # my to convert Month Year strings/ints into proper date format month(dates) # returns 4 5 12 year(dates) # returns 2020 2024 2020 Full Documentation "],["misc..html", "Chapter 5 Misc.", " Chapter 5 Misc. month.name is a list in R that can be indexed by each month’s number. slice_max(col, n=5) for top 5 and slice_min(col, n=5) for bottom 5 by values of col. state.name is a default list in R that contains US state names in title case. Useful for checking if a string is a US state. Example: mutate(State = ifelse(State %in% state.name,State,NA)) unique(Col) is useful for checking work on qualitative columns. head() (for the first couple of rows) or sample() (for random rows) can give you a quick subset of your dataframe to view. To get value not in the list, you can use !(Value %in% List) Country code library can convert all types of country spellings to standard type: countrycode(Country, origin = 'country.name', destination = 'iso3c') "],["practice-problems-1.html", "Chapter 6 Practice Problems 6.1 R Project Redone", " Chapter 6 Practice Problems 6.1 R Project Redone knitr::opts_chunk$set(echo = TRUE, message=FALSE, warning=FALSE) library(tidyverse) data &lt;- read.csv(file = &quot;~/Downloads/project_data_file.csv&quot;) print(data) ## Birth_Month_Year State Country ## 1 December, 1999 North Carolina United States ## 2 7, 1998 Virginia United States ## 3 April, 1999 North Carolina United States of America ## 4 November, 1999 California United States ## 5 June, 1991 Kentucky USA ## 6 December, 1999 North Carolina United States of America ## 7 May, 2000 Texas South Korea ## 8 January, 1998 Tennessee South Korea ## 9 October, 1998 NC USA ## 10 November, 2001 Illinois US ## 11 April, 2000 NC U.S. ## 12 October, 1997 Taiwan ## 13 December, 1997 NC China ## 14 October, 2001 North Carolina United States ## 15 June, 1995 NC USA ## 16 June, 2001 North Carolina United States ## 17 September, 1996 North Carolina United States ## 18 October, 1999 Texas USA ## 19 September, 2000 North Carolina United States ## 20 May, 2001 North Carolina United States ## 21 February, 1994 NC South Korea ## 22 June, 2002 North Carolina United States of America ## 23 February , 1999 North Carolina USA ## 24 November, 1999 North Carolina USA ## 25 11, 2000 NC US ## 26 August, 2000 Telangana India ## 27 August, 2001 North Carolina United States of America ## 28 October, 2000 North Carolina Uruguay ## 29 May, 1995 Georgia South Korea ## 30 October , 1989 NC China ## 31 July, 2001 NC ## 32 June, 1999 North Carolina United States ## 33 August, 1999 NC Mexico ## 34 January, 2001 South Carolina The United States ## 35 August, 2000 North Carolina USA ## 36 July, 2001 Alabama United States ## 37 May, 2001 Connecticut USA ## 38 October, 1990 North Carolina USA ## 39 May, 1995 North Carolina US ## 40 September, 2000 Wisconsin USA ## 41 June, 2000 North Carolina United States ## 42 February, 1996 Illinois USA ## 43 May, 2001 North Carolina United States ## 44 October , 1999 JiangSu China ## 45 May, 2001 NC USA ## 46 October, 1991 New York United States ## 47 December , 1999 North Carolina United States ## 48 May, 2000 Florida USA ## 49 March, 2001 North Carolina The United States ## 50 June, 2001 North Carolina United States ## 51 December, 2000 North Carolina United States ## 52 February, 2001 NC USA ## 53 January, 1995 &lt;NA&gt; Singapore ## 54 April, 2001 North Carolina United States ## 55 February, 2002 North Carolina United States ## 56 February, 2001 North Carolina USA ## 57 March, 1998 Utah United States ## 58 March, 1995 North Carolina USA ## 59 August, 1996 NC US ## 60 June, 2000 North Carolina United States ## 61 February, 2002 North Carolina United States ## 62 October, 2000 NC USA ## 63 August , 2001 Texas United States ## 64 9, 1993 NC United States ## 65 October, 2000 Florida United States of America ## 66 February, 2001 Massachusetts USA ## 67 May, 2001 North Carolina United States ## 68 May, 1999 NC USA ## 69 February, 1971 Guatemala Guatemala ## 70 May, 1993 Lima Peru ## 71 October, 1979 Anambra Nigeria ## 72 September, 1998 Telangana India ## 73 March, 1999 New Jersey United States ## 74 January, 2002 North Carolina United States ## 75 September, 2001 Minnesota USA ## 76 April, North Carolina Durham ## 77 June, 2001 North Carolina United States ## 78 September , 2000 North Carolina United States ## 79 November, 2000 Massachusetts United States ## 80 January, 2000 Pennsylvania United States ## 81 October, 1999 California United States of America ## 82 September, 1990 North Carolina United States of America ## 83 December, 1992 Pennsylvania United States ## 84 September, 2000 California U.S.A ## 85 May, 1999 North Carolina U.S. ## 86 July, 2001 North Carolina United States ## 87 August, 1994 Myanmar ## 88 November, 1987 Taoyuan Taiwan ## 89 April, 2000 North Carolina USA ## 90 august, 2001 arizona united states ## 91 February, 2001 North Carolina United States ## 92 December, 1997 Lagos Nigeria ## 93 July, 1996 Karnataka India ## 94 December, 1999 North Carolina United States ## 95 April , North Carolina United States of America ## 96 April, 1998 NC USA ## Languages When_Hear_About_Program ## 1 English 1-2 years ## 2 English, Spanish 1-2 years ## 3 English 3-5 years ## 4 English Less than one year ago ## 5 English 1-2 years ## 6 English Less than one year ago ## 7 English, Korean Less than one year ago ## 8 English, Korean 1-2 years ## 9 English, Spanish 3-5 years ## 10 English 1-2 years ## 11 English, Spanish, Chinese 1-2 years ## 12 English, Chinese Less than one year ago ## 13 English, Chinese 1-2 years ## 14 English 1-2 years ## 15 English, Spanish 1-2 years ## 16 English, Telugu 3-5 years ## 17 English, Japanese Less than one year ago ## 18 English Less than one year ago ## 19 English 1-2 years ## 20 English Less than one year ago ## 21 English, Korean 3-5 years ## 22 English 1-2 years ## 23 English, Spanish 1-2 years ## 24 English, Spanish, Telugu 3-5 years ## 25 English, Chinese 1-2 years ## 26 English, Telugu, Hindi 1-2 years ## 27 English 1-2 years ## 28 English, Spanish 1-2 years ## 29 English, Korean 3-5 years ## 30 English, Chinese Less than one year ago ## 31 English 1-2 years ## 32 English, Spanish Less than one year ago ## 33 English, Spanish Less than one year ago ## 34 English Less than one year ago ## 35 English, 1-2 years ## 36 English Less than one year ago ## 37 English Less than one year ago ## 38 English 1-2 years ## 39 English, Spanish 1-2 years ## 40 English 1-2 years ## 41 English, Spanish, Italian 1-2 years ## 42 English, French 1-2 years ## 43 English Less than one year ago ## 44 English, Chinese 1-2 years ## 45 English, Chinese Less than one year ago ## 46 English 1-2 years ## 47 English 1-2 years ## 48 English, Chinese Less than one year ago ## 49 English 1-2 years ## 50 English 1-2 years ## 51 English, Hindi 1-2 years ## 52 English 1-2 years ## 53 English, Spanish, Chinese 1-2 years ## 54 English 3-5 years ## 55 English Less than one year ago ## 56 English, Chinese 1-2 years ## 57 English 3-5 years ## 58 English Less than one year ago ## 59 English 6-8 years ## 60 English 3-5 years ## 61 English 3-5 years ## 62 English, Spanish 1-2 years ## 63 English Less than one year ago ## 64 English 6-8 years ## 65 English, Spanish Less than one year ago ## 66 English, Russian 1-2 years ## 67 English Less than one year ago ## 68 English, Spanish, Chinese 1-2 years ## 69 English, Spanish 1-2 years ## 70 English, Spanish 3-5 years ## 71 English 3-5 years ## 72 English, Telugu 1-2 years ## 73 English, Telugu 1-2 years ## 74 English 1-2 years ## 75 English Less than one year ago ## 76 English Less than one year ago ## 77 English Less than one year ago ## 78 English 1-2 years ## 79 English Less than one year ago ## 80 English 1-2 years ## 81 English 1-2 years ## 82 English 3-5 years ## 83 English 3-5 years ## 84 English, Vietnamese Less than one year ago ## 85 English, Spanish 3-5 years ## 86 English 1-2 years ## 87 English, Chinese, Burmese 1-2 years ## 88 English, Chinese, Taiwanese 6-8 years ## 89 English, Spanish, Gujarati 3-5 years ## 90 English Less than one year ago ## 91 English Less than one year ago ## 92 English Less than one year ago ## 93 English, Kannada , Tamil Less than one year ago ## 94 English 1-2 years ## 95 English 1-2 years ## 96 English, Japanese 1-2 years ## How_Hear_About_Program ## 1 1. Recommended by professors ## 2 2. Recommended by family/friends ## 3 2. Recommended by family/friends ## 4 2. Recommended by family/friends ## 5 4. Search engine ## 6 4. Search engine ## 7 1. Recommended by professors ## 8 2. Recommended by family/friends ## 9 2. Recommended by family/friends ## 10 2. Recommended by family/friends ## 11 4. Search engine ## 12 4. Search engine ## 13 4. Search engine ## 14 2. Recommended by family/friends ## 15 2. Recommended by family/friends ## 16 2. Recommended by family/friends ## 17 1. Recommended by professors ## 18 2. Recommended by family/friends ## 19 2. Recommended by family/friends ## 20 4. Search engine ## 21 2. Recommended by family/friends ## 22 4. Search engine ## 23 2. Recommended by family/friends ## 24 1. Recommended by professors ## 25 2. Recommended by family/friends ## 26 5. Recommendations found in blogs ## 27 2. Recommended by family/friends ## 28 1. Recommended by professors ## 29 2. Recommended by family/friends ## 30 4. Search engine ## 31 2. Recommended by family/friends ## 32 3. On social media (Twitter, Instagram, FB) ## 33 4. Search engine ## 34 4. Search engine ## 35 2. Recommended by family/friends ## 36 1. Recommended by professors ## 37 2. Recommended by family/friends ## 38 2. Recommended by family/friends ## 39 2. Recommended by family/friends ## 40 4. Search engine ## 41 2. Recommended by family/friends ## 42 4. Search engine ## 43 2. Recommended by family/friends ## 44 2. Recommended by family/friends ## 45 1. Recommended by professors ## 46 4. Search engine ## 47 2. Recommended by family/friends ## 48 4. Search engine ## 49 2. Recommended by family/friends ## 50 4. Search engine ## 51 2. Recommended by family/friends ## 52 3. On social media (Twitter, Instagram, FB) ## 53 4. Search engine ## 54 2. Recommended by family/friends ## 55 1. Recommended by professors ## 56 2. Recommended by family/friends ## 57 2. Recommended by family/friends ## 58 4. Search engine ## 59 2. Recommended by family/friends ## 60 2. Recommended by family/friends ## 61 2. Recommended by family/friends ## 62 2. Recommended by family/friends ## 63 2. Recommended by family/friends ## 64 2. Recommended by family/friends ## 65 4. Search engine ## 66 2. Recommended by family/friends ## 67 4. Search engine ## 68 2. Recommended by family/friends ## 69 2. Recommended by family/friends ## 70 2. Recommended by family/friends ## 71 4. Search engine ## 72 4. Search engine ## 73 2. Recommended by family/friends ## 74 1. Recommended by professors ## 75 4. Search engine ## 76 3. On social media (Twitter, Instagram, FB) ## 77 2. Recommended by family/friends ## 78 1. Recommended by professors ## 79 1. Recommended by professors ## 80 4. Search engine ## 81 4. Search engine ## 82 2. Recommended by family/friends ## 83 2. Recommended by family/friends ## 84 4. Search engine ## 85 4. Search engine ## 86 4. Search engine ## 87 2. Recommended by family/friends ## 88 2. Recommended by family/friends ## 89 2. Recommended by family/friends ## 90 2. Recommended by family/friends ## 91 2. Recommended by family/friends ## 92 5. Recommendations found in blogs ## 93 4. Search engine ## 94 1. Recommended by professors ## 95 3. On social media (Twitter, Instagram, FB) ## 96 1. Recommended by professors ## Hobbies ## 1 Video Games, Sports ## 2 Movies, Television Series, Sports, Outside Recreational Activities ## 3 Sports, Art, Music ## 4 Video Games, Outside Recreational Activities, Art ## 5 Movies, Video Games, Music, Reading ## 6 Movies, Television Series, Video Games, Sports, Outside Recreational Activities, Podcasts ## 7 Sports, Outside Recreational Activities ## 8 Movies, Video Games, Music, Dance ## 9 Outside Recreational Activities, Music ## 10 Movies, Outside Recreational Activities ## 11 Movies, Video Games, Sports, Outside Recreational Activities, Music ## 12 Movies, Television Series, Sports ## 13 Movies, Television Series, Video Games, Art, Music ## 14 Movies, Television Series, Outside Recreational Activities ## 15 Salsa Dancing, Hot Yoga, Working out ## 16 Sports, Music ## 17 Movies, Outside Recreational Activities, Art, Gardening ## 18 Movies, Outside Recreational Activities, Music ## 19 Video Games, Sports, Outside Recreational Activities, Music ## 20 Video Games, Outside Recreational Activities, Music ## 21 Movies, Sports, Music ## 22 Sports, Outside Recreational Activities ## 23 Outside Recreational Activities ## 24 Television Series, Sports, Outside Recreational Activities ## 25 Television Series, window shopping ## 26 Movies, Television Series, Art ## 27 Movies, Outside Recreational Activities, Music ## 28 Movies, Sports, Outside Recreational Activities, Music ## 29 Movies, Outside Recreational Activities, Music, Weightlifting, Cooking, Traveling ## 30 Movies, Television Series, Explore cities and restaurants ## 31 Television Series, Outside Recreational Activities ## 32 Movies, Sports, Outside Recreational Activities, Theater, Dance, Reading, Writing ## 33 Movies, Outside Recreational Activities ## 34 Video Games, Sports, Card / Board Games ## 35 Television Series, Outside Recreational Activities ## 36 Sports, Outside Recreational Activities, Art, Cooking ## 37 Outside Recreational Activities ## 38 Outside Recreational Activities, Reading ## 39 Movies, Television Series, Art, sewing, crochet ## 40 Sports, Outside Recreational Activities ## 41 Movies, Television Series, Video Games, Sports, Outside Recreational Activities, Music, Board and card games ## 42 Outside Recreational Activities, Music ## 43 Movies, Outside Recreational Activities ## 44 Sports ## 45 Movies, Television Series, Outside Recreational Activities, Art ## 46 Movies, Television Series ## 47 Television Series, Sports, Outside Recreational Activities, Music ## 48 Movies, Television Series, Video Games, Sports, Outside Recreational Activities, Music ## 49 Movies, Television Series, Outside Recreational Activities ## 50 Movies, Television Series, Sports ## 51 Movies, Outside Recreational Activities ## 52 Television Series, Sports, Outside Recreational Activities ## 53 Movies, Television Series, Sports, Outside Recreational Activities, Music ## 54 Movies, Television Series, Sports, Outside Recreational Activities ## 55 Video Games, Sports, Outside Recreational Activities ## 56 Television Series, Outside Recreational Activities, Music ## 57 Movies, Television Series, Sports, Outside Recreational Activities ## 58 Sports, Outside Recreational Activities, Cooking and checking out local businesses! ## 59 Television Series, Outside Recreational Activities ## 60 Movies, Video Games, Sports, Outside Recreational Activities, Art ## 61 Movies, Television Series, Outside Recreational Activities, Art, Music ## 62 Movies, Television Series, Video Games, Sports, Outside Recreational Activities, Music ## 63 Movies, Television Series, Art ## 64 Movies, Sports, Music ## 65 Video Games ## 66 Video Games, Outside Recreational Activities ## 67 Television Series, Video Games, Music ## 68 Movies, Video Games, Sports, Outside Recreational Activities, Art ## 69 Movies, Television Series, Sports ## 70 Movies, Television Series, Sports ## 71 Television Series, Sports, Outside Recreational Activities ## 72 Movies, Television Series, Outside Recreational Activities, Art ## 73 Television Series, Sports, Outside Recreational Activities, Music ## 74 Television Series, Outside Recreational Activities ## 75 Television Series, Sports, Outside Recreational Activities, Music ## 76 Digital Jigsaw Puzzles ## 77 Television Series, Outside Recreational Activities, Music ## 78 Sports, Exercise ## 79 Movies, Television Series, Sports ## 80 Movies, Television Series, Video Games, Sports, Outside Recreational Activities, Music, Read ## 81 Movies, Television Series, Video Games, Art, Music ## 82 Movies, Television Series, Video Games, Sports, Outside Recreational Activities ## 83 Television Series, Video Games, Sports, Music ## 84 Sports ## 85 Movies, Television Series, Sports, Outside Recreational Activities, Music ## 86 Television Series ## 87 Video Games, Sports, Art ## 88 Sports ## 89 Television Series, Video Games, Sports, Outside Recreational Activities ## 90 Sports, Outside Recreational Activities, Music ## 91 Television Series ## 92 Video Games, Sports ## 93 Movies, Television Series, Music ## 94 Video Games, Sports ## 95 Digital Jigsaw Puzzles ## 96 Movies, Television Series, Video Games, Outside Recreational Activities, Music, Reading 6.1.1 1 and 2 Create a new column called Birth_Month which has only the month portion of Birth_Month_Year. Create a new column called Birth_Year which has only the year portion of Birth_Month_Year. data_alt &lt;- data %&gt;% separate_wider_delim(Birth_Month_Year, delim=&quot;,&quot;, names = c(&quot;Birth_Month&quot;, &quot;Birth_Year&quot;)) print(data_alt) ## # A tibble: 96 × 8 ## Birth_Month Birth_Year State Country Languages When_Hear_About_Prog…¹ ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 December &quot; 1999&quot; North Caroli… United… English 1-2 years ## 2 7 &quot; 1998&quot; Virginia United… English,… 1-2 years ## 3 April &quot; 1999&quot; North Caroli… United… English 3-5 years ## 4 November &quot; 1999&quot; California United… English Less than one year ago ## 5 June &quot; 1991&quot; Kentucky USA English 1-2 years ## 6 December &quot; 1999&quot; North Caroli… United… English Less than one year ago ## 7 May &quot; 2000&quot; Texas South … English,… Less than one year ago ## 8 January &quot; 1998&quot; Tennessee South … English,… 1-2 years ## 9 October &quot; 1998&quot; NC USA English,… 3-5 years ## 10 November &quot; 2001&quot; Illinois US English 1-2 years ## # ℹ 86 more rows ## # ℹ abbreviated name: ¹​When_Hear_About_Program ## # ℹ 2 more variables: How_Hear_About_Program &lt;chr&gt;, Hobbies &lt;chr&gt; 6.1.2 3 and 4 Since the birth month and birth year were open ended fields, there are many inconsistencies in the data. Standardize the values for Birth_Month and Birth_Year. Show the five most frequent birth months, and the five least frequent birth months. data_alt2 &lt;- data_alt %&gt;% mutate(Birth_Month = case_when( Birth_Month == &quot;7&quot; ~ &quot;July&quot;, Birth_Month == &quot;11&quot; ~ &quot;November&quot;, Birth_Month == &quot;9&quot; ~ &quot;September&quot;, .default = Birth_Month)) %&gt;% mutate(Birth_Month = str_to_title(str_trim(Birth_Month))) %&gt;% mutate(Birth_Year = as.numeric(str_trim(Birth_Year))) print(data_alt2) ## # A tibble: 96 × 8 ## Birth_Month Birth_Year State Country Languages When_Hear_About_Prog…¹ ## &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 December 1999 North Caroli… United… English 1-2 years ## 2 July 1998 Virginia United… English,… 1-2 years ## 3 April 1999 North Caroli… United… English 3-5 years ## 4 November 1999 California United… English Less than one year ago ## 5 June 1991 Kentucky USA English 1-2 years ## 6 December 1999 North Caroli… United… English Less than one year ago ## 7 May 2000 Texas South … English,… Less than one year ago ## 8 January 1998 Tennessee South … English,… 1-2 years ## 9 October 1998 NC USA English,… 3-5 years ## 10 November 2001 Illinois US English 1-2 years ## # ℹ 86 more rows ## # ℹ abbreviated name: ¹​When_Hear_About_Program ## # ℹ 2 more variables: How_Hear_About_Program &lt;chr&gt;, Hobbies &lt;chr&gt; data_alt2 %&gt;% count(Birth_Month, sort = TRUE) %&gt;% head(5) ## # A tibble: 5 × 2 ## Birth_Month n ## &lt;chr&gt; &lt;int&gt; ## 1 October 13 ## 2 May 12 ## 3 February 10 ## 4 June 9 ## 5 September 9 data_alt2 %&gt;% count(Birth_Month, sort = TRUE) %&gt;% tail(5) ## # A tibble: 5 × 2 ## Birth_Month n ## &lt;chr&gt; &lt;int&gt; ## 1 April 7 ## 2 November 6 ## 3 January 5 ## 4 July 5 ## 5 March 4 data_alt2 %&gt;% count(Birth_Year, sort = TRUE) %&gt;% head(5) ## # A tibble: 5 × 2 ## Birth_Year n ## &lt;dbl&gt; &lt;int&gt; ## 1 2001 24 ## 2 2000 19 ## 3 1999 16 ## 4 1998 6 ## 5 1995 5 data_alt2 %&gt;% count(Birth_Year, sort = TRUE) %&gt;% tail(5) ## # A tibble: 5 × 2 ## Birth_Year n ## &lt;dbl&gt; &lt;int&gt; ## 1 1971 1 ## 2 1979 1 ## 3 1987 1 ## 4 1989 1 ## 5 1992 1 6.1.3 6 and 7 data_alt3 &lt;- data_alt2 %&gt;% mutate(State = ifelse(State %in% state.name,State,NA)) print(data_alt3) ## # A tibble: 96 × 8 ## Birth_Month Birth_Year State Country Languages When_Hear_About_Prog…¹ ## &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 December 1999 North Caroli… United… English 1-2 years ## 2 July 1998 Virginia United… English,… 1-2 years ## 3 April 1999 North Caroli… United… English 3-5 years ## 4 November 1999 California United… English Less than one year ago ## 5 June 1991 Kentucky USA English 1-2 years ## 6 December 1999 North Caroli… United… English Less than one year ago ## 7 May 2000 Texas South … English,… Less than one year ago ## 8 January 1998 Tennessee South … English,… 1-2 years ## 9 October 1998 &lt;NA&gt; USA English,… 3-5 years ## 10 November 2001 Illinois US English 1-2 years ## # ℹ 86 more rows ## # ℹ abbreviated name: ¹​When_Hear_About_Program ## # ℹ 2 more variables: How_Hear_About_Program &lt;chr&gt;, Hobbies &lt;chr&gt; 6.1.4 9 data_alt4 &lt;- data_alt3 %&gt;% rowwise() %&gt;% mutate(How_Hear_About_Program = substring(How_Hear_About_Program, 4, nchar(How_Hear_About_Program))) %&gt;% ungroup() print(data_alt4) ## # A tibble: 96 × 8 ## Birth_Month Birth_Year State Country Languages When_Hear_About_Prog…¹ ## &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 December 1999 North Caroli… United… English 1-2 years ## 2 July 1998 Virginia United… English,… 1-2 years ## 3 April 1999 North Caroli… United… English 3-5 years ## 4 November 1999 California United… English Less than one year ago ## 5 June 1991 Kentucky USA English 1-2 years ## 6 December 1999 North Caroli… United… English Less than one year ago ## 7 May 2000 Texas South … English,… Less than one year ago ## 8 January 1998 Tennessee South … English,… 1-2 years ## 9 October 1998 &lt;NA&gt; USA English,… 3-5 years ## 10 November 2001 Illinois US English 1-2 years ## # ℹ 86 more rows ## # ℹ abbreviated name: ¹​When_Hear_About_Program ## # ℹ 2 more variables: How_Hear_About_Program &lt;chr&gt;, Hobbies &lt;chr&gt; 6.1.5 "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
